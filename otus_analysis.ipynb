{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from easynmt import EasyNMT"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "SRC_LANG = \"en\"\n",
    "TRG_LANG = \"ru\"\n",
    "\n",
    "MODEL_TYPE = \"opus-mt\"\n",
    "MODEL_NAME = f\"Helsinki-NLP/opus-mt-{SRC_LANG}-{TRG_LANG}\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "model = EasyNMT(MODEL_TYPE)\n",
    "translator = model.translator.load_model(MODEL_NAME)"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "sentences = [\n",
    "    \"A caravan of fifty two camels slowly made its way through the desert.\",\n",
    "    \"Wood may remain ten years in the water, but it will never become a crocodile.\",\n",
    "    \"The horse raced past the barn fell.\",\n",
    "    \"We haven't really spoken much since your return.\",\n",
    "    \"I'll bring the wine glasses.\",\n",
    "    \"This is the best tasting pear I've ever eaten.\",\n",
    "    \"Dentists recommend to change toothbrushes every three months, because over time their bristles become worse at getting rid of plague, as well as accumulate microbes.\",\n",
    "    \"Your boss was so impressed with your skills, she gave you a raise.\",\n",
    "]\n",
    "\n",
    "model.translate(sentences, source_lang=SRC_LANG, target_lang=TRG_LANG)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/negativex/School/research/tda-mt/.venv/lib/python3.9/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Караван из пятидесяти двух верблюдов медленно прошел через пустыню.',\n",
       " 'Древесина может оставаться в воде десять лет, но она никогда не станет крокодилом.',\n",
       " 'Лошадь бежала мимо амбара.',\n",
       " 'Мы почти ничего не говорили с тех пор, как вы вернулись.',\n",
       " 'Я принесу винные очки.',\n",
       " 'Это лучший вкус груши, который я когда-либо ел.',\n",
       " 'Дантисты рекомендуют менять зубные щетки каждые три месяца, потому что со временем их щетки становятся еще хуже, когда они избавляются от чумы, а также накапливают микробы.',\n",
       " 'Твой босс был так впечатлен твоими навыками, что она дала тебе повышение.']"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Извлечение Encoder Attention"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from utils.attn_extraction import get_attn_scores"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "tokenizer = model.translator.models[\"Helsinki-NLP/opus-mt-en-ru\"][\"tokenizer\"]\n",
    "translator = model.translator.models[\"Helsinki-NLP/opus-mt-en-ru\"][\"model\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import inspect\n",
    "\n",
    "inspect.signature(translator.model.decoder.layers[0].encoder_attn.forward)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<Signature (hidden_states: torch.Tensor, key_value_states: Optional[torch.Tensor] = None, past_key_value: Optional[Tuple[torch.Tensor]] = None, attention_mask: Optional[torch.Tensor] = None, layer_head_mask: Optional[torch.Tensor] = None, output_attentions: bool = False) -> Tuple[torch.Tensor, Optional[torch.Tensor], Optional[Tuple[torch.Tensor]]]>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hooks do not capture kwargs in pytorch ([issue](https://github.com/pytorch/pytorch/issues/35643)). Seems like input is passed to attention as kwarg, hence the hook does not capture any input."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* What to do with beam search? Depending on `beam_size` amount of passes through decoder layer changes\n",
    "\n",
    "    | beam size       | 1  | 2  | 3  | 4  | 5  | 6  | ... | 10 |\n",
    "    | --------------- | -- | -- | -- | -- | -- | -- | --- | -- |\n",
    "    | output \"tokens\" | 20 | 21 | 21 | 23 | 23 | 23 | ... | 23 |\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "a = get_attn_scores(sentences[1], model, MODEL_NAME, SRC_LANG, TRG_LANG)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "for idx, sentence in enumerate(sentences[:3]):\n",
    "    tokenization = tokenizer([sentence], truncation=True, padding=True, return_tensors=\"pt\")\n",
    "    input_tokens = tokenizer.convert_ids_to_tokens(tokenization[\"input_ids\"][0])\n",
    "    with torch.no_grad():\n",
    "        translated = translator.generate(**tokenization, num_beams=5)\n",
    "        output_tokens = tokenizer.convert_ids_to_tokens(translated[0])[1:]  # first token is always <pad>\n",
    "    \n",
    "    print(f\"Input ({len(input_tokens)} tokens):\", *input_tokens)\n",
    "    print(f\"Output ({len(output_tokens)} tokens):\", *output_tokens)\n",
    "    print()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Input (16 tokens): ▁A ▁caravan ▁of ▁fifty ▁two ▁came ls ▁slowly ▁made ▁its ▁way ▁through ▁the ▁desert . </s>\n",
      "Output (18 tokens): ▁Кар аван ▁из ▁пятидесят и ▁двух ▁в ер блюд ов ▁медленно ▁прошел ▁через ▁пуст ы ню . </s>\n",
      "\n",
      "Input (18 tokens): ▁Wood ▁may ▁remain ▁ten ▁years ▁in ▁the ▁water , ▁but ▁it ▁will ▁never ▁become ▁a ▁crocodile . </s>\n",
      "Output (23 tokens): ▁Д ре вес ина ▁может ▁оставаться ▁в ▁воде ▁десять ▁лет , ▁но ▁она ▁никогда ▁не ▁станет ▁к рок од ил ом . </s>\n",
      "\n",
      "Input (11 tokens): ▁The ▁horse ▁race d ▁past ▁the ▁bar n ▁fell . </s>\n",
      "Output (15 tokens): ▁Ло ша д ь ▁ бежал а ▁ мимо ▁а м бар а . </s>\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def prep_graph(inc_mat, input_tokens, output_tokens):\n",
    "    input_tokens = [\"src \" + tok for tok in input_tokens]\n",
    "    output_tokens = [\"tgt \" + tok for tok in output_tokens]\n",
    "\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(input_tokens, bipartite=0)\n",
    "    G.add_nodes_from(output_tokens, bipartite=1)\n",
    "\n",
    "    G.add_edges_from([(output_tokens[i], input_tokens[j]) for i, j in np.argwhere(inc_mat).T.numpy()])\n",
    "\n",
    "    pos = {}\n",
    "    pos.update((node, (1, index)) for index, node in enumerate(input_tokens[::-1]))\n",
    "    pos.update((node, (2, index)) for index, node in enumerate(output_tokens[::-1]))\n",
    "\n",
    "    return G, pos"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "source": [
    "thresh = 0.25\n",
    "\n",
    "layer_of_interest = 5\n",
    "\n",
    "hook_name = f\"decoder_l{layer_of_interest}\"\n",
    "head_attn = a[hook_name]\n",
    "for idx, sentence in enumerate(sentences):\n",
    "    tokenization = tokenizer([sentence], truncation=True, padding=True, return_tensors=\"pt\")\n",
    "    input_tokens = tokenizer.convert_ids_to_tokens(tokenization[\"input_ids\"][0])\n",
    "    with torch.no_grad():\n",
    "        translated = translator.generate(**tokenization, num_beams=5)\n",
    "        output_tokens = tokenizer.convert_ids_to_tokens(translated[0])\n",
    "    print(get_attn_scores([sentence], model, MODEL_NAME, SRC_LANG, TRG_LANG)[\"decoder_l0\"].shape)\n",
    "    print(input_tokens, len(input_tokens))\n",
    "    print(output_tokens, len(output_tokens))\n",
    "    attn = F.normalize(head_attn)\n",
    "    inc_mat = (attn > thresh).int()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 20, 512])\n",
      "['▁A', '▁caravan', '▁of', '▁fifty', '▁two', '▁came', 'ls', '▁slowly', '▁made', '▁its', '▁way', '▁through', '▁the', '▁desert', '.', '</s>'] 16\n",
      "['<pad>', '▁Кар', 'аван', '▁из', '▁пятидесят', 'и', '▁двух', '▁в', 'ер', 'блюд', 'ов', '▁медленно', '▁прошел', '▁через', '▁пуст', 'ы', 'ню', '.', '</s>'] 19\n",
      "torch.Size([1, 23, 512])\n",
      "['▁Wood', '▁may', '▁remain', '▁ten', '▁years', '▁in', '▁the', '▁water', ',', '▁but', '▁it', '▁will', '▁never', '▁become', '▁a', '▁crocodile', '.', '</s>'] 18\n",
      "['<pad>', '▁Д', 'ре', 'вес', 'ина', '▁может', '▁оставаться', '▁в', '▁воде', '▁десять', '▁лет', ',', '▁но', '▁она', '▁никогда', '▁не', '▁станет', '▁к', 'рок', 'од', 'ил', 'ом', '.', '</s>'] 24\n",
      "torch.Size([1, 14, 512])\n",
      "['▁The', '▁horse', '▁race', 'd', '▁past', '▁the', '▁bar', 'n', '▁fell', '.', '</s>'] 11\n",
      "['<pad>', '▁Ло', 'ша', 'д', 'ь', '▁', 'бежал', 'а', '▁', 'мимо', '▁а', 'м', 'бар', 'а', '.', '</s>'] 16\n",
      "torch.Size([1, 14, 512])\n",
      "['▁We', '▁haven', \"'\", 't', '▁really', '▁spoken', '▁much', '▁since', '▁your', '▁return', '.', '</s>'] 12\n",
      "['<pad>', '▁Мы', '▁почти', '▁ничего', '▁не', '▁говорили', '▁с', '▁тех', '▁пор', ',', '▁как', '▁вы', '▁вернулись', '.', '</s>'] 15\n",
      "torch.Size([1, 10, 512])\n",
      "['▁I', \"'\", 'll', '▁bring', '▁the', '▁wine', '▁glass', 'es', '.', '</s>'] 10\n",
      "['<pad>', '▁Я', '▁принес', 'у', '▁в', 'и', 'нные', '▁о', 'чки', '.', '</s>'] 11\n",
      "torch.Size([1, 16, 512])\n",
      "['▁This', '▁is', '▁the', '▁best', '▁ta', 's', 'ting', '▁p', 'ear', '▁I', \"'\", 've', '▁ever', '▁eaten', '.', '</s>'] 16\n",
      "['<pad>', '▁Это', '▁лучший', '▁вкус', '▁г', 'руш', 'и', ',', '▁который', '▁я', '▁когда', '-', 'либо', '▁', 'ел', '.', '</s>'] 17\n",
      "torch.Size([1, 43, 512])\n",
      "['▁D', 'ent', 'ists', '▁recommend', '▁to', '▁change', '▁to', 'oth', 'b', 'rush', 'es', '▁every', '▁three', '▁months', ',', '▁because', '▁over', '▁time', '▁their', '▁b', 'rist', 'les', '▁become', '▁worse', '▁at', '▁getting', '▁rid', '▁of', '▁plague', ',', '▁as', '▁well', '▁as', '▁accumulate', '▁micro', 'be', 's', '.', '</s>'] 39\n",
      "['<pad>', '▁Д', 'ант', 'исты', '▁рекомендуют', '▁менять', '▁зуб', 'ные', '▁', 'ще', 'тки', '▁каждые', '▁три', '▁месяца', ',', '▁потому', '▁что', '▁со', '▁временем', '▁их', '▁', 'ще', 'тки', '▁становятся', '▁еще', '▁хуже', ',', '▁когда', '▁они', '▁избавля', 'ются', '▁от', '▁ч', 'у', 'мы', ',', '▁а', '▁также', '▁накаплива', 'ют', '▁микро', 'бы', '.', '</s>'] 44\n",
      "torch.Size([1, 20, 512])\n",
      "['▁Your', '▁boss', '▁was', '▁so', '▁impressed', '▁with', '▁your', '▁skills', ',', '▁she', '▁gave', '▁you', '▁a', '▁raise', '.', '</s>'] 16\n",
      "['<pad>', '▁Т', 'вой', '▁бо', 'сс', '▁был', '▁так', '▁в', 'печат', 'лен', '▁твои', 'ми', '▁навыками', ',', '▁что', '▁она', '▁дала', '▁тебе', '▁повышение', '.', '</s>'] 21\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('.venv': venv)"
  },
  "interpreter": {
   "hash": "f46dbfbc06b85bfa399c3f1e19d52b9e5842bc23723244878e740f9b0f429d7f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}